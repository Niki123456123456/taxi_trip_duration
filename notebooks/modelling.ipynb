{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Setup & Imports",
   "id": "a0d5a60dd549e5f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-18T03:21:12.223943Z",
     "start_time": "2025-06-18T03:21:12.217602Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "import pandas as pd\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import RandomizedSearchCV, train_test_split\n",
    "\n",
    "import preModelling.data_config as config\n",
    "from modelling.GeoClusterer import GeoClusterer\n",
    "from modelling.feature_config import NUM_ALL, CAT_ALL, BOOL_ALL\n",
    "from modelling.feature_importance import plot_lin_feature_importance, \\\n",
    "  plot_tree_feature_importance\n",
    "from modelling.modelling_config import (\n",
    "  N_PICKUP_CLUSTERS, N_DROPOFF_CLUSTERS, RANDOM_SEED, KMEANS_BATCH_SIZE\n",
    ")\n",
    "from modelling.modelling_utils import make_all_models, feature_to_category, \\\n",
    "  feature_as_bool\n",
    "from modelling.transformer import build_haversine_transformer, \\\n",
    "  make_linear_pipeline\n",
    "from modelling.transformer import get_display_models_results, \\\n",
    "  compare_models_results\n",
    "from modelling.transformer import (\n",
    "  num_base_pipelining,\n",
    "  cat_base_pipelining,\n",
    "  bool_base_pipelining\n",
    ")"
   ],
   "id": "a3673db47b16301e",
   "outputs": [],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-18T02:17:22.595390Z",
     "start_time": "2025-06-18T02:17:18.732331Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load taxi and weather data\n",
    "taxi_weather_df = pd.read_csv(config.TAXI_WEATHER_DATA_SAVE)\n",
    "\n",
    "for dt in [\"pickup_datetime\", \"dropoff_datetime\"]:\n",
    "  taxi_weather_df[dt] = pd.to_datetime(taxi_weather_df[dt])\n",
    "\n",
    "taxi_weather_df = feature_to_category(taxi_weather_df, CAT_ALL)\n",
    "taxi_weather_df = feature_as_bool(taxi_weather_df, BOOL_ALL)\n",
    "\n",
    "taxi_weather_df = taxi_weather_df.drop(columns=[\"id\", 'dropoff_datetime', \"pickup_datetime\"\n",
    "                                                ], errors=\"ignore\")"
   ],
   "id": "66184c84eada8cc",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Train/Test Split",
   "id": "b1435a95842a4f3b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-18T02:17:24.136415Z",
     "start_time": "2025-06-18T02:17:23.933391Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# everything until 31-05-2016 as a Training Base\n",
    "TARGET_COL = 'trip_duration_log'\n",
    "\n",
    "train_df, test_df = train_test_split(taxi_weather_df, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train, y_train = train_df.drop(columns=[TARGET_COL]), train_df[TARGET_COL]\n",
    "\n",
    "X_holdout, y_holdout = test_df.drop(columns=[TARGET_COL]), test_df[TARGET_COL]"
   ],
   "id": "40e27e9a0fc5e3e9",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Preprocessing-Configuration",
   "id": "123729d1b4343dbb"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-18T02:17:26.178289Z",
     "start_time": "2025-06-18T02:17:26.174065Z"
    }
   },
   "cell_type": "code",
   "source": [
    "num_pipe = num_base_pipelining()\n",
    "cat_pipe = cat_base_pipelining()\n",
    "bool_pipe = bool_base_pipelining()\n",
    "\n",
    "geo_pick = GeoClusterer(\n",
    "    cols=['pickup_longitude', 'pickup_latitude'],\n",
    "    n_clusters=N_PICKUP_CLUSTERS,\n",
    "    random_state=RANDOM_SEED,\n",
    "    batch_size=KMEANS_BATCH_SIZE\n",
    ")\n",
    "geo_drop = GeoClusterer(\n",
    "    cols=['dropoff_longitude', 'dropoff_latitude'],\n",
    "    n_clusters=N_DROPOFF_CLUSTERS,\n",
    "    random_state=RANDOM_SEED,\n",
    "    batch_size=KMEANS_BATCH_SIZE\n",
    ")\n",
    "hav_trans = build_haversine_transformer()\n",
    "\n",
    "preprocessing = ColumnTransformer(\n",
    "    transformers=[\n",
    "      ('num', num_pipe, NUM_ALL),\n",
    "      ('cat', cat_pipe, CAT_ALL),\n",
    "      ('bool', bool_pipe, BOOL_ALL),\n",
    "      ('g_pick', geo_pick, ['pickup_longitude', 'pickup_latitude']),\n",
    "      ('g_drop', geo_drop, ['dropoff_longitude', 'dropoff_latitude']),\n",
    "      ('hav', hav_trans,\n",
    "       ['pickup_latitude', 'pickup_longitude',\n",
    "        'dropoff_latitude', 'dropoff_longitude']),\n",
    "    ],\n",
    "    remainder=\"drop\",\n",
    ")"
   ],
   "id": "3eb38da5461c4fff",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Hyperparameter search",
   "id": "8db282d426445cb2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-18T03:55:39.883053Z",
     "start_time": "2025-06-18T03:55:39.865777Z"
    }
   },
   "cell_type": "code",
   "source": [
    "param_dist_xgb = {\n",
    "  'model__n_estimators': [200, 400, 800],\n",
    "  'model__max_depth': [6, 10],\n",
    "  'model__learning_rate': [0.03, 0.1],\n",
    "  'model__subsample': [0.8, 1.0],\n",
    "  'model__colsample_bytree': [0.7, 0.9],\n",
    "  'model__gamma': [0, 1],\n",
    "}\n",
    "param_dist_lgbm = {\n",
    "  'model__n_estimators': [400, 700, 1000],\n",
    "  'model__learning_rate': [0.05, 0.1, 0.2],\n",
    "  'model__max_depth': [-1, 8, 12],\n",
    "  'model__num_leaves': [31, 63, 127],\n",
    "  'model__feature_fraction': [0.7, 0.9, 1.0],\n",
    "  'model__bagging_fraction': [0.7, 0.9, 1.0],\n",
    "  'model__bagging_freq': [0, 1],\n",
    "}\n",
    "\n",
    "# ----------------------  XGBoost  ---------------------------------\n",
    "param_dist_xgb_fast = {\n",
    "  \"model__n_estimators\": [150, 300],  # weniger Bäume\n",
    "  \"model__max_depth\": [6, 9],  # zwei sinnvolle Tiefen\n",
    "  \"model__learning_rate\": [0.05],  # guter Mittelwert\n",
    "  \"model__subsample\": [0.8],  # nur 0.8 (meist besser)\n",
    "  \"model__colsample_bytree\": [0.8],  # dito\n",
    "  \"model__gamma\": [0],  # selten nötig: nur 0\n",
    "}\n",
    "\n",
    "# ----------------------  LightGBM  --------------------------------\n",
    "param_dist_lgbm_fast = {\n",
    "  \"model__n_estimators\": [300, 600],  # halb so viele Kombis\n",
    "  \"model__learning_rate\": [0.05, 0.1],  # zwei LR-Stufen\n",
    "  \"model__max_depth\": [-1, 8],  # -1 (keine Grenze) oder 8\n",
    "  \"model__num_leaves\": [31, 63],  # üblich für obige depth\n",
    "  \"model__feature_fraction\": [0.8, 1.0],  # 80 % oder alle Features\n",
    "  \"model__bagging_fraction\": [0.8],  # nur eine Variante\n",
    "  \"model__bagging_freq\": [0],  # kein Bagging\n",
    "}\n",
    "\n",
    "param_dist_linreg = {\n",
    "  \"model__fit_intercept\": [True, False],\n",
    "  \"model__positive\": [True, False],\n",
    "}\n",
    "\n",
    "param_dist_ridge = {\"model__alpha\": [0.1, 1.0, 10, 20]}\n",
    "\n",
    "param_dist_lasso = {\n",
    "  # log-uniform draws values everywhere between 1e-4 and 10\n",
    "  \"model__alpha\": [0.1, 1.0, 10, 20],\n",
    "\n",
    "  # try with/without intercept\n",
    "  \"model__fit_intercept\": [True, False],\n",
    "\n",
    "  # try both CD update orders\n",
    "  \"model__selection\": [\"cyclic\", \"random\"],\n",
    "}\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# DecisionTreeRegressor\n",
    "# ------------------------------------------------------------------\n",
    "from scipy.stats import randint  # if you want real dists\n",
    "\n",
    "param_dist_dt = {\n",
    "  # model__ prefix because the step is named \"model\"\n",
    "  \"model__max_depth\": [None, 5, 10, 15, 20],\n",
    "\n",
    "  \"model__min_samples_split\": randint(2, 20),  # 2–19\n",
    "  \"model__min_samples_leaf\": randint(1, 10),  # 1–9\n",
    "\n",
    "  # valid options only – no \"auto\"\n",
    "  \"model__max_features\": [\"sqrt\", \"log2\", None, 0.3, 0.5],\n",
    "\n",
    "  # post-pruning strength, draw small non-negatives\n",
    "  \"model__ccp_alpha\": [0.0, 0.001, 0.02]  # 0.000…0.02\n",
    "}\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# RandomForestRegressor\n",
    "# ------------------------------------------------------------------\n",
    "param_dist_rf_fast = {\n",
    "  \"model__n_estimators\": (50, 100),\n",
    "  \"model__max_depth\": [10, 20],\n",
    "  \"model__min_samples_split\": (2, 8),  # 2-7\n",
    "  \"model__min_samples_leaf\": (1, 4),  # 1-3\n",
    "  \"model__max_features\": [\"sqrt\", 0.3, 0.5],  # keine langsamen Varianten\n",
    "  \"model__bootstrap\": [True],  # OOB-Metrik möglich\n",
    "}\n",
    "\n",
    "param_dist_rf = {\n",
    "  \"model__n_estimators\": randint(200, 1001),  # 200–1000\n",
    "\n",
    "  \"model__max_depth\": [None, 10, 20, 30],\n",
    "  \"model__min_samples_split\": randint(2, 15),\n",
    "  \"model__min_samples_leaf\": randint(1, 8),\n",
    "\n",
    "  # again: no \"auto\"\n",
    "  \"model__max_features\": [\"sqrt\", \"log2\", None, 0.3, 0.5],\n",
    "\n",
    "  \"model__bootstrap\": [True, False],\n",
    "}"
   ],
   "id": "de168c404245e0dc",
   "outputs": [],
   "execution_count": 33
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Lin reg",
   "id": "c3f9b3688ff029c7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-18T02:20:24.245858Z",
     "start_time": "2025-06-18T02:19:41.489919Z"
    }
   },
   "cell_type": "code",
   "source": [
    "linreg_pipeline = make_linear_pipeline('linreg', preprocessing)\n",
    "\n",
    "search_linreg = RandomizedSearchCV(linreg_pipeline,\n",
    "                                   param_dist_linreg,\n",
    "                                   cv=4,\n",
    "                                   n_iter=4,\n",
    "                                   scoring='neg_root_mean_squared_error',\n",
    "                                   random_state=RANDOM_SEED,\n",
    "                                   n_jobs=-1)\n",
    "\n",
    "search_linreg.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best Lin Reg CV score log-RMSE:\", -search_linreg.best_score_)\n",
    "print(\"Best Lin Reg hyper-parameters:   \", search_linreg.best_params_)\n",
    "\n",
    "best_linreg_model = search_linreg.best_estimator_\n",
    "y_linreg_pred = best_linreg_model.predict(X_holdout)\n",
    "linreg_rmse = mean_squared_error(y_holdout, y_linreg_pred)\n",
    "\n",
    "print(\"Hold-out Lin Reg RMSE:\", linreg_rmse)"
   ],
   "id": "9aeadaf30a21a0de",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Lin Reg CV score log-RMSE: 0.5619142017252576\n",
      "Best Lin Reg hyper-parameters:    {'model__positive': False, 'model__fit_intercept': True}\n",
      "Hold-out Lin Reg RMSE: 0.319040919360973\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Ridge",
   "id": "5bf36256ba704ba9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-18T02:29:44.835771Z",
     "start_time": "2025-06-18T02:29:26.215591Z"
    }
   },
   "cell_type": "code",
   "source": [
    "ridge_pipeline = make_linear_pipeline('ridge', preprocessing)\n",
    "\n",
    "search_ridge = RandomizedSearchCV(ridge_pipeline,\n",
    "                                  param_dist_ridge,\n",
    "                                  cv=4,\n",
    "                                  n_iter=4,\n",
    "                                  scoring='neg_root_mean_squared_error',\n",
    "                                  random_state=RANDOM_SEED,\n",
    "                                  n_jobs=-1)\n",
    "\n",
    "search_ridge.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best Ridge CV score log-RMSE:\", -search_ridge.best_score_)\n",
    "print(\"Best Ridge hyper-parameters:   \", search_ridge.best_params_)\n",
    "\n",
    "best_ridge_model = search_ridge.best_estimator_\n",
    "y_ridge_pred = best_ridge_model.predict(X_holdout)\n",
    "ridge_rmse = mean_squared_error(y_holdout, y_ridge_pred)\n",
    "\n",
    "print(\"Hold-out Ridge RMSE:\", ridge_rmse)"
   ],
   "id": "971bed8b0c5fd684",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Lin Reg CV score log-RMSE: 0.5619141660460274\n",
      "Best Lin Reg hyper-parameters:    {'model__alpha': 20}\n",
      "Hold-out Lin Reg RMSE: 0.3190410200018535\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Lasso",
   "id": "d40fa7008c9c64db"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-18T02:39:26.465822Z",
     "start_time": "2025-06-18T02:37:46.255511Z"
    }
   },
   "cell_type": "code",
   "source": [
    "lasso_pipeline = make_linear_pipeline('lasso', preprocessing)\n",
    "\n",
    "search_lasso = RandomizedSearchCV(lasso_pipeline,\n",
    "                                  param_dist_lasso,\n",
    "                                  n_iter=16,  # ~10 draws per dimension is plenty\n",
    "                                  cv=3,\n",
    "                                  scoring='neg_root_mean_squared_error',\n",
    "                                  random_state=RANDOM_SEED,\n",
    "                                  n_jobs=-1)\n",
    "\n",
    "search_lasso.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best Lasso CV score log-RMSE:\", -search_lasso.best_score_)\n",
    "print(\"Best Lasso hyper-parameters:   \", search_lasso.best_params_)\n",
    "\n",
    "best_lasso_model = search_lasso.best_estimator_\n",
    "y_lasso_pred = best_lasso_model.predict(X_holdout)\n",
    "lasso_rmse = mean_squared_error(y_holdout, y_lasso_pred)\n",
    "\n",
    "print(\"Hold-out Lasso RMSE:\", lasso_rmse)"
   ],
   "id": "b4956148c2e1ffb4",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Wendo99/miniconda3/envs/NYC_Taxi/lib/python3.12/site-packages/sklearn/model_selection/_search.py:317: UserWarning: The total space of parameters 16 is smaller than n_iter=40. Running 16 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Lasso CV score log-RMSE: 0.5689098420165003\n",
      "Best Lasso hyper-parameters:    {'model__selection': 'cyclic', 'model__fit_intercept': True, 'model__alpha': 0.1}\n",
      "Hold-out Lasso RMSE: 0.32528923830330053\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Decision Tree",
   "id": "5917c55ab23db81e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-18T03:19:08.320439Z",
     "start_time": "2025-06-18T03:11:58.591554Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "dt_pipeline = Pipeline(\n",
    "    steps=[\n",
    "      (\"prep\", preprocessing),  # ← your ColumnTransformer\n",
    "      (\"model\", DecisionTreeRegressor(\n",
    "          random_state=RANDOM_SEED,  # reproducibility\n",
    "          # --- sensible defaults you can tune later ------------------\n",
    "          max_depth=None,\n",
    "          min_samples_split=2,\n",
    "          min_samples_leaf=1,\n",
    "      )),\n",
    "    ],\n",
    "    memory=None,  # reuse the joblib cache if you like\n",
    ")\n",
    "\n",
    "search_dt = RandomizedSearchCV(\n",
    "    dt_pipeline,\n",
    "    param_distributions=param_dist_dt,\n",
    "    n_iter=40,\n",
    "    cv=3,\n",
    "    scoring=\"neg_root_mean_squared_error\",\n",
    "    random_state=RANDOM_SEED,\n",
    "    n_jobs=-1,\n",
    "    error_score=\"raise\"  # <- helps you catch bad params immediately\n",
    ")\n",
    "\n",
    "search_dt.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best dt CV score log-RMSE:\", -search_dt.best_score_)\n",
    "print(\"Best dt hyper-parameters:   \", search_dt.best_params_)\n",
    "\n",
    "best_dt_model = search_dt.best_estimator_\n",
    "y_dt_pred = best_dt_model.predict(X_holdout)\n",
    "dt_rmse = mean_squared_error(y_holdout, y_dt_pred)\n",
    "\n",
    "print(\"Hold-out dt RMSE:\", dt_rmse)\n",
    "\n"
   ],
   "id": "41a51a84229c4d33",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Wendo99/miniconda3/envs/NYC_Taxi/lib/python3.12/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best dt CV score log-RMSE: 0.4094025557207141\n",
      "Best dt hyper-parameters:    {'model__ccp_alpha': 0.0, 'model__max_depth': 10, 'model__max_features': None, 'model__min_samples_leaf': 9, 'model__min_samples_split': 6}\n",
      "Hold-out dt RMSE: 0.16931029095142222\n"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Random Forest",
   "id": "afa76c9f19825a6e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-18T05:03:48.106054Z",
     "start_time": "2025-06-18T04:21:40.118842Z"
    }
   },
   "cell_type": "code",
   "source": [
    "rf_pipeline = Pipeline(\n",
    "    steps=[\n",
    "      (\"prep\", preprocessing),  # ← your ColumnTransformer\n",
    "      (\"model\", RandomForestRegressor(\n",
    "          random_state=RANDOM_SEED,  # reproducibility\n",
    "          # --- sensible defaults you can tune later ------------------\n",
    "          max_depth=None,\n",
    "          min_samples_split=2,\n",
    "          min_samples_leaf=1,\n",
    "      )),\n",
    "    ],\n",
    "    memory=None,  # reuse the joblib cache if you like\n",
    ")\n",
    "\n",
    "search_rf = RandomizedSearchCV(\n",
    "    rf_pipeline,\n",
    "    param_distributions=param_dist_rf,\n",
    "    n_iter=80,\n",
    "    cv=3,\n",
    "    scoring=\"neg_root_mean_squared_error\",\n",
    "    random_state=RANDOM_SEED,\n",
    "    n_jobs=-1,\n",
    "    error_score=\"raise\"\n",
    ")\n",
    "\n",
    "search_rf_fast = RandomizedSearchCV(\n",
    "    rf_pipeline,\n",
    "    param_distributions=param_dist_rf_fast,\n",
    "    n_iter=20,\n",
    "    cv=3,\n",
    "    scoring=\"neg_root_mean_squared_error\",\n",
    "    random_state=RANDOM_SEED,\n",
    "    n_jobs=-1,\n",
    "    verbose=2,\n",
    ")\n",
    "\n",
    "search_rf_fast.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best rf CV score log-RMSE:\", -search_rf_fast.best_score_)\n",
    "print(\"Best rf hyper-parameters:   \", search_rf_fast.best_params_)\n",
    "\n",
    "best_rf_model = search_rf_fast.best_estimator_\n",
    "y_rf_pred = best_rf_model.predict(X_holdout)\n",
    "rf_rmse = mean_squared_error(y_holdout, y_rf_pred)\n",
    "\n",
    "print(\"Hold-out rf RMSE:\", rf_rmse)\n",
    "\n"
   ],
   "id": "728d958536ce778f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 30 candidates, totalling 90 fits\n",
      "[CV] END model__bootstrap=True, model__max_depth=10, model__max_features=sqrt, model__min_samples_leaf=3, model__min_samples_split=7, model__n_estimators=102; total time= 1.6min\n",
      "[CV] END model__bootstrap=True, model__max_depth=10, model__max_features=sqrt, model__min_samples_leaf=3, model__min_samples_split=7, model__n_estimators=102; total time= 1.6min\n",
      "[CV] END model__bootstrap=True, model__max_depth=10, model__max_features=sqrt, model__min_samples_leaf=3, model__min_samples_split=7, model__n_estimators=102; total time= 1.7min\n",
      "[CV] END model__bootstrap=True, model__max_depth=10, model__max_features=sqrt, model__min_samples_leaf=3, model__min_samples_split=4, model__n_estimators=121; total time= 1.9min\n",
      "[CV] END model__bootstrap=True, model__max_depth=10, model__max_features=sqrt, model__min_samples_leaf=3, model__min_samples_split=4, model__n_estimators=121; total time= 1.9min\n",
      "[CV] END model__bootstrap=True, model__max_depth=10, model__max_features=sqrt, model__min_samples_leaf=3, model__min_samples_split=4, model__n_estimators=121; total time= 2.0min\n",
      "[CV] END model__bootstrap=True, model__max_depth=10, model__max_features=sqrt, model__min_samples_leaf=3, model__min_samples_split=3, model__n_estimators=124; total time= 2.0min\n",
      "[CV] END model__bootstrap=True, model__max_depth=10, model__max_features=sqrt, model__min_samples_leaf=3, model__min_samples_split=3, model__n_estimators=124; total time= 2.0min\n",
      "[CV] END model__bootstrap=True, model__max_depth=10, model__max_features=sqrt, model__min_samples_leaf=3, model__min_samples_split=3, model__n_estimators=124; total time= 2.0min\n",
      "[CV] END model__bootstrap=True, model__max_depth=20, model__max_features=0.3, model__min_samples_leaf=2, model__min_samples_split=3, model__n_estimators=70; total time= 3.0min\n",
      "[CV] END model__bootstrap=True, model__max_depth=20, model__max_features=0.3, model__min_samples_leaf=2, model__min_samples_split=3, model__n_estimators=70; total time= 2.9min\n",
      "[CV] END model__bootstrap=True, model__max_depth=20, model__max_features=0.3, model__min_samples_leaf=2, model__min_samples_split=3, model__n_estimators=70; total time= 2.9min\n",
      "[CV] END model__bootstrap=True, model__max_depth=10, model__max_features=0.5, model__min_samples_leaf=3, model__min_samples_split=3, model__n_estimators=64; total time= 2.6min\n",
      "[CV] END model__bootstrap=True, model__max_depth=10, model__max_features=0.5, model__min_samples_leaf=3, model__min_samples_split=3, model__n_estimators=64; total time= 2.6min\n",
      "[CV] END model__bootstrap=True, model__max_depth=10, model__max_features=0.5, model__min_samples_leaf=3, model__min_samples_split=3, model__n_estimators=64; total time= 2.7min\n",
      "[CV] END model__bootstrap=True, model__max_depth=10, model__max_features=0.3, model__min_samples_leaf=2, model__min_samples_split=6, model__n_estimators=138; total time= 3.5min\n",
      "[CV] END model__bootstrap=True, model__max_depth=10, model__max_features=0.3, model__min_samples_leaf=2, model__min_samples_split=6, model__n_estimators=138; total time= 3.4min\n",
      "[CV] END model__bootstrap=True, model__max_depth=10, model__max_features=0.3, model__min_samples_leaf=2, model__min_samples_split=6, model__n_estimators=138; total time= 3.5min\n",
      "[CV] END model__bootstrap=True, model__max_depth=20, model__max_features=0.3, model__min_samples_leaf=3, model__min_samples_split=7, model__n_estimators=100; total time= 4.1min\n",
      "[CV] END model__bootstrap=True, model__max_depth=10, model__max_features=0.3, model__min_samples_leaf=2, model__min_samples_split=3, model__n_estimators=58; total time= 1.6min\n",
      "[CV] END model__bootstrap=True, model__max_depth=20, model__max_features=0.3, model__min_samples_leaf=3, model__min_samples_split=7, model__n_estimators=100; total time= 4.1min\n",
      "[CV] END model__bootstrap=True, model__max_depth=10, model__max_features=sqrt, model__min_samples_leaf=1, model__min_samples_split=3, model__n_estimators=181; total time= 2.7min\n",
      "[CV] END model__bootstrap=True, model__max_depth=10, model__max_features=0.3, model__min_samples_leaf=2, model__min_samples_split=3, model__n_estimators=58; total time= 1.5min\n",
      "[CV] END model__bootstrap=True, model__max_depth=10, model__max_features=sqrt, model__min_samples_leaf=1, model__min_samples_split=3, model__n_estimators=181; total time= 2.7min\n",
      "[CV] END model__bootstrap=True, model__max_depth=10, model__max_features=sqrt, model__min_samples_leaf=1, model__min_samples_split=3, model__n_estimators=181; total time= 2.7min\n",
      "[CV] END model__bootstrap=True, model__max_depth=10, model__max_features=0.3, model__min_samples_leaf=2, model__min_samples_split=3, model__n_estimators=58; total time= 1.5min\n",
      "[CV] END model__bootstrap=True, model__max_depth=20, model__max_features=0.3, model__min_samples_leaf=3, model__min_samples_split=7, model__n_estimators=100; total time= 4.1min\n",
      "[CV] END model__bootstrap=True, model__max_depth=20, model__max_features=sqrt, model__min_samples_leaf=2, model__min_samples_split=5, model__n_estimators=141; total time= 3.4min\n",
      "[CV] END model__bootstrap=True, model__max_depth=20, model__max_features=sqrt, model__min_samples_leaf=2, model__min_samples_split=5, model__n_estimators=141; total time= 3.3min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Wendo99/miniconda3/envs/NYC_Taxi/lib/python3.12/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END model__bootstrap=True, model__max_depth=20, model__max_features=sqrt, model__min_samples_leaf=2, model__min_samples_split=5, model__n_estimators=141; total time= 3.3min\n",
      "[CV] END model__bootstrap=True, model__max_depth=20, model__max_features=0.5, model__min_samples_leaf=1, model__min_samples_split=4, model__n_estimators=100; total time= 6.8min\n",
      "[CV] END model__bootstrap=True, model__max_depth=20, model__max_features=0.5, model__min_samples_leaf=1, model__min_samples_split=4, model__n_estimators=100; total time= 7.0min\n",
      "[CV] END model__bootstrap=True, model__max_depth=20, model__max_features=0.5, model__min_samples_leaf=1, model__min_samples_split=4, model__n_estimators=100; total time= 6.8min\n",
      "[CV] END model__bootstrap=True, model__max_depth=10, model__max_features=0.5, model__min_samples_leaf=1, model__min_samples_split=4, model__n_estimators=130; total time= 5.3min\n",
      "[CV] END model__bootstrap=True, model__max_depth=10, model__max_features=0.5, model__min_samples_leaf=1, model__min_samples_split=4, model__n_estimators=130; total time= 5.3min\n",
      "[CV] END model__bootstrap=True, model__max_depth=10, model__max_features=0.5, model__min_samples_leaf=1, model__min_samples_split=4, model__n_estimators=130; total time= 5.3min\n",
      "[CV] END model__bootstrap=True, model__max_depth=20, model__max_features=0.3, model__min_samples_leaf=2, model__min_samples_split=7, model__n_estimators=63; total time= 2.5min\n",
      "[CV] END model__bootstrap=True, model__max_depth=20, model__max_features=0.3, model__min_samples_leaf=2, model__min_samples_split=7, model__n_estimators=63; total time= 2.4min\n",
      "[CV] END model__bootstrap=True, model__max_depth=20, model__max_features=0.3, model__min_samples_leaf=2, model__min_samples_split=7, model__n_estimators=63; total time= 2.4min\n",
      "[CV] END model__bootstrap=True, model__max_depth=20, model__max_features=0.3, model__min_samples_leaf=2, model__min_samples_split=7, model__n_estimators=183; total time= 7.3min\n",
      "[CV] END model__bootstrap=True, model__max_depth=10, model__max_features=sqrt, model__min_samples_leaf=2, model__min_samples_split=6, model__n_estimators=73; total time= 1.1min\n",
      "[CV] END model__bootstrap=True, model__max_depth=10, model__max_features=sqrt, model__min_samples_leaf=2, model__min_samples_split=6, model__n_estimators=73; total time= 1.1min\n",
      "[CV] END model__bootstrap=True, model__max_depth=10, model__max_features=0.5, model__min_samples_leaf=2, model__min_samples_split=5, model__n_estimators=89; total time= 3.6min\n",
      "[CV] END model__bootstrap=True, model__max_depth=10, model__max_features=0.5, model__min_samples_leaf=2, model__min_samples_split=5, model__n_estimators=89; total time= 3.6min\n",
      "[CV] END model__bootstrap=True, model__max_depth=20, model__max_features=0.3, model__min_samples_leaf=2, model__min_samples_split=7, model__n_estimators=183; total time= 7.2min\n",
      "[CV] END model__bootstrap=True, model__max_depth=20, model__max_features=0.3, model__min_samples_leaf=2, model__min_samples_split=7, model__n_estimators=183; total time= 7.2min\n",
      "[CV] END model__bootstrap=True, model__max_depth=10, model__max_features=sqrt, model__min_samples_leaf=2, model__min_samples_split=6, model__n_estimators=73; total time= 1.1min\n",
      "[CV] END model__bootstrap=True, model__max_depth=20, model__max_features=sqrt, model__min_samples_leaf=1, model__min_samples_split=2, model__n_estimators=64; total time= 1.6min\n",
      "[CV] END model__bootstrap=True, model__max_depth=20, model__max_features=0.3, model__min_samples_leaf=2, model__min_samples_split=6, model__n_estimators=195; total time= 7.8min\n",
      "[CV] END model__bootstrap=True, model__max_depth=20, model__max_features=sqrt, model__min_samples_leaf=1, model__min_samples_split=2, model__n_estimators=64; total time= 1.6min\n",
      "[CV] END model__bootstrap=True, model__max_depth=20, model__max_features=0.3, model__min_samples_leaf=2, model__min_samples_split=6, model__n_estimators=195; total time= 7.7min\n",
      "[CV] END model__bootstrap=True, model__max_depth=20, model__max_features=sqrt, model__min_samples_leaf=1, model__min_samples_split=2, model__n_estimators=64; total time= 1.6min\n",
      "[CV] END model__bootstrap=True, model__max_depth=20, model__max_features=0.3, model__min_samples_leaf=2, model__min_samples_split=6, model__n_estimators=195; total time= 7.7min\n",
      "[CV] END model__bootstrap=True, model__max_depth=10, model__max_features=0.5, model__min_samples_leaf=2, model__min_samples_split=5, model__n_estimators=89; total time= 3.7min\n",
      "[CV] END model__bootstrap=True, model__max_depth=10, model__max_features=sqrt, model__min_samples_leaf=1, model__min_samples_split=2, model__n_estimators=137; total time= 2.0min\n",
      "[CV] END model__bootstrap=True, model__max_depth=10, model__max_features=sqrt, model__min_samples_leaf=1, model__min_samples_split=2, model__n_estimators=137; total time= 1.9min\n",
      "[CV] END model__bootstrap=True, model__max_depth=10, model__max_features=sqrt, model__min_samples_leaf=1, model__min_samples_split=2, model__n_estimators=137; total time= 2.0min\n",
      "[CV] END model__bootstrap=True, model__max_depth=10, model__max_features=0.3, model__min_samples_leaf=3, model__min_samples_split=3, model__n_estimators=90; total time= 2.2min\n",
      "[CV] END model__bootstrap=True, model__max_depth=10, model__max_features=0.3, model__min_samples_leaf=3, model__min_samples_split=3, model__n_estimators=90; total time= 2.2min\n",
      "[CV] END model__bootstrap=True, model__max_depth=10, model__max_features=0.3, model__min_samples_leaf=3, model__min_samples_split=3, model__n_estimators=90; total time= 2.2min\n",
      "[CV] END model__bootstrap=True, model__max_depth=10, model__max_features=0.5, model__min_samples_leaf=3, model__min_samples_split=4, model__n_estimators=130; total time= 5.1min\n",
      "[CV] END model__bootstrap=True, model__max_depth=10, model__max_features=0.5, model__min_samples_leaf=3, model__min_samples_split=4, model__n_estimators=130; total time= 5.1min\n",
      "[CV] END model__bootstrap=True, model__max_depth=10, model__max_features=0.5, model__min_samples_leaf=3, model__min_samples_split=4, model__n_estimators=130; total time= 5.1min\n",
      "[CV] END model__bootstrap=True, model__max_depth=20, model__max_features=0.5, model__min_samples_leaf=1, model__min_samples_split=5, model__n_estimators=82; total time= 5.2min\n",
      "[CV] END model__bootstrap=True, model__max_depth=20, model__max_features=0.5, model__min_samples_leaf=1, model__min_samples_split=5, model__n_estimators=82; total time= 5.0min\n",
      "[CV] END model__bootstrap=True, model__max_depth=20, model__max_features=0.5, model__min_samples_leaf=1, model__min_samples_split=5, model__n_estimators=82; total time= 5.0min\n",
      "[CV] END model__bootstrap=True, model__max_depth=20, model__max_features=0.5, model__min_samples_leaf=3, model__min_samples_split=7, model__n_estimators=86; total time= 5.2min\n",
      "[CV] END model__bootstrap=True, model__max_depth=10, model__max_features=0.3, model__min_samples_leaf=3, model__min_samples_split=4, model__n_estimators=150; total time= 3.4min\n",
      "[CV] END model__bootstrap=True, model__max_depth=10, model__max_features=0.3, model__min_samples_leaf=3, model__min_samples_split=2, model__n_estimators=54; total time= 1.3min\n",
      "[CV] END model__bootstrap=True, model__max_depth=10, model__max_features=0.3, model__min_samples_leaf=3, model__min_samples_split=2, model__n_estimators=54; total time= 1.3min\n",
      "[CV] END model__bootstrap=True, model__max_depth=10, model__max_features=0.3, model__min_samples_leaf=3, model__min_samples_split=4, model__n_estimators=150; total time= 3.5min\n",
      "[CV] END model__bootstrap=True, model__max_depth=10, model__max_features=0.3, model__min_samples_leaf=3, model__min_samples_split=2, model__n_estimators=54; total time= 1.3min\n",
      "[CV] END model__bootstrap=True, model__max_depth=20, model__max_features=0.5, model__min_samples_leaf=3, model__min_samples_split=7, model__n_estimators=86; total time= 5.2min\n",
      "[CV] END model__bootstrap=True, model__max_depth=20, model__max_features=0.5, model__min_samples_leaf=3, model__min_samples_split=7, model__n_estimators=86; total time= 5.2min\n",
      "[CV] END model__bootstrap=True, model__max_depth=20, model__max_features=0.5, model__min_samples_leaf=3, model__min_samples_split=2, model__n_estimators=172; total time=10.5min\n",
      "[CV] END model__bootstrap=True, model__max_depth=20, model__max_features=0.5, model__min_samples_leaf=3, model__min_samples_split=2, model__n_estimators=172; total time=10.5min\n",
      "[CV] END model__bootstrap=True, model__max_depth=20, model__max_features=0.5, model__min_samples_leaf=3, model__min_samples_split=2, model__n_estimators=172; total time=10.6min\n",
      "[CV] END model__bootstrap=True, model__max_depth=10, model__max_features=0.3, model__min_samples_leaf=3, model__min_samples_split=4, model__n_estimators=150; total time= 3.6min\n",
      "[CV] END model__bootstrap=True, model__max_depth=10, model__max_features=sqrt, model__min_samples_leaf=3, model__min_samples_split=3, model__n_estimators=91; total time= 1.3min\n",
      "[CV] END model__bootstrap=True, model__max_depth=10, model__max_features=sqrt, model__min_samples_leaf=3, model__min_samples_split=3, model__n_estimators=91; total time= 1.3min\n",
      "[CV] END model__bootstrap=True, model__max_depth=10, model__max_features=sqrt, model__min_samples_leaf=3, model__min_samples_split=3, model__n_estimators=91; total time= 1.3min\n",
      "[CV] END model__bootstrap=True, model__max_depth=20, model__max_features=sqrt, model__min_samples_leaf=3, model__min_samples_split=2, model__n_estimators=101; total time= 2.1min\n",
      "[CV] END model__bootstrap=True, model__max_depth=20, model__max_features=sqrt, model__min_samples_leaf=3, model__min_samples_split=2, model__n_estimators=101; total time= 2.1min\n",
      "[CV] END model__bootstrap=True, model__max_depth=20, model__max_features=sqrt, model__min_samples_leaf=3, model__min_samples_split=2, model__n_estimators=101; total time= 2.1min\n",
      "[CV] END model__bootstrap=True, model__max_depth=10, model__max_features=0.3, model__min_samples_leaf=1, model__min_samples_split=6, model__n_estimators=192; total time= 3.7min\n",
      "[CV] END model__bootstrap=True, model__max_depth=10, model__max_features=0.3, model__min_samples_leaf=1, model__min_samples_split=6, model__n_estimators=192; total time= 3.7min\n",
      "[CV] END model__bootstrap=True, model__max_depth=10, model__max_features=0.3, model__min_samples_leaf=1, model__min_samples_split=6, model__n_estimators=192; total time= 3.6min\n",
      "[CV] END model__bootstrap=True, model__max_depth=20, model__max_features=0.5, model__min_samples_leaf=3, model__min_samples_split=7, model__n_estimators=152; total time= 7.5min\n",
      "[CV] END model__bootstrap=True, model__max_depth=20, model__max_features=0.5, model__min_samples_leaf=3, model__min_samples_split=7, model__n_estimators=152; total time= 7.2min\n",
      "[CV] END model__bootstrap=True, model__max_depth=20, model__max_features=0.5, model__min_samples_leaf=3, model__min_samples_split=7, model__n_estimators=152; total time= 7.2min\n",
      "Best rf CV score log-RMSE: 0.39754111369803\n",
      "Best rf hyper-parameters:    {'model__bootstrap': True, 'model__max_depth': 20, 'model__max_features': 0.3, 'model__min_samples_leaf': 2, 'model__min_samples_split': 7, 'model__n_estimators': 183}\n",
      "Hold-out rf RMSE: 0.1597386353082649\n"
     ]
    }
   ],
   "execution_count": 37
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-18T04:21:39.746335Z",
     "start_time": "2025-06-18T04:20:38.166060Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from xgboost import XGBRegressor\n",
    "\n",
    "xgb_pipeline = Pipeline(\n",
    "    steps=[\n",
    "      (\"prep\", preprocessing),\n",
    "      (\"model\", XGBRegressor(\n",
    "          objective=\"reg:squarederror\",\n",
    "          random_state=RANDOM_SEED,\n",
    "          n_jobs=-1,\n",
    "          enable_categorical=True,  # lets pandas categories through\n",
    "      )),\n",
    "    ],\n",
    "    memory=None,\n",
    ")\n",
    "\n",
    "search_xgb = RandomizedSearchCV(\n",
    "    xgb_pipeline,\n",
    "    param_distributions=param_dist_xgb_fast,\n",
    "    n_iter=8,  # 2×2×1×1×1×1 = 4  → 8 Samples decken alles ab\n",
    "    cv=3,\n",
    "    scoring=\"neg_root_mean_squared_error\",\n",
    "    random_state=RANDOM_SEED,\n",
    "    n_jobs=-1,\n",
    ")\n",
    "\n",
    "search_xgb.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best xgb CV score log-RMSE:\", -search_xgb.best_score_)\n",
    "print(\"Best xgb hyper-parameters:   \", search_xgb.best_params_)\n",
    "\n",
    "best_xgb_model = search_xgb.best_estimator_\n",
    "y_xgb_pred = best_xgb_model.predict(X_holdout)\n",
    "xgb_rmse = mean_squared_error(y_holdout, y_xgb_pred)\n",
    "\n",
    "print(\"Hold-out xgb RMSE:\", xgb_rmse)"
   ],
   "id": "1b80505fb2531d9d",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Wendo99/miniconda3/envs/NYC_Taxi/lib/python3.12/site-packages/sklearn/model_selection/_search.py:317: UserWarning: The total space of parameters 4 is smaller than n_iter=8. Running 4 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best xgb CV score log-RMSE: 0.3957739854488404\n",
      "Best xgb hyper-parameters:    {'model__subsample': 0.8, 'model__n_estimators': 300, 'model__max_depth': 9, 'model__learning_rate': 0.05, 'model__gamma': 0, 'model__colsample_bytree': 0.8}\n",
      "Hold-out xgb RMSE: 0.15892652155664427\n"
     ]
    }
   ],
   "execution_count": 36
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-18T04:20:37.834443Z",
     "start_time": "2025-06-18T04:15:21.033876Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "lgbm_pipeline = Pipeline(\n",
    "    steps=[\n",
    "      (\"prep\", preprocessing),  # your ColumnTransformer\n",
    "      (\"model\", LGBMRegressor(\n",
    "          objective=\"regression\",\n",
    "          metric=\"rmse\",\n",
    "          random_state=RANDOM_SEED,\n",
    "          n_jobs=-1,\n",
    "          # no enable_categorical here—after preprocessing features are numeric\n",
    "      )),\n",
    "    ],\n",
    "    memory=None,\n",
    ")\n",
    "\n",
    "search_lgbm = RandomizedSearchCV(\n",
    "    lgbm_pipeline,\n",
    "    param_distributions=param_dist_lgbm_fast,\n",
    "    n_iter=12,  # 2×2×2×2×2×1×1 = 32 → 12 Zufallssamples reichen\n",
    "    cv=3,\n",
    "    scoring=\"neg_root_mean_squared_error\",\n",
    "    random_state=RANDOM_SEED,\n",
    "    n_jobs=-1,\n",
    ")\n",
    "\n",
    "search_lgbm.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best LGBM CV log-RMSE:\", -search_lgbm.best_score_)\n",
    "print(\"Best LGBM hyper-parameters:\", search_lgbm.best_params_)\n",
    "\n",
    "best_lgbm_model = search_lgbm.best_estimator_\n",
    "y_lgbm_pred = best_lgbm_model.predict(X_holdout)\n",
    "lgbm_rmse = mean_squared_error(y_holdout, y_lgbm_pred)\n",
    "print(\"Hold-out LGBM RMSE:\", lgbm_rmse)"
   ],
   "id": "8949c080cddb7405",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.061050 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1729\n",
      "[LightGBM] [Info] Number of data points in the train set: 777943, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 6.469957\n",
      "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.163099 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1729\n",
      "[LightGBM] [Info] Number of data points in the train set: 777943, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 6.469957\n",
      "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.367253 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1729\n",
      "[LightGBM] [Info] Number of data points in the train set: 777943, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 6.469957\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.236859 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1724\n",
      "[LightGBM] [Info] Number of data points in the train set: 777943, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 6.470364\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.280405 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1729\n",
      "[LightGBM] [Info] Number of data points in the train set: 777943, number of used features: 34\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.166466 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1718\n",
      "[LightGBM] [Info] Start training from score 6.469957\n",
      "[LightGBM] [Info] Number of data points in the train set: 777944, number of used features: 34\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.176728 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1718\n",
      "[LightGBM] [Info] Start training from score 6.468315\n",
      "[LightGBM] [Info] Number of data points in the train set: 777944, number of used features: 34\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.205320 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1724\n",
      "[LightGBM] [Info] Start training from score 6.468315\n",
      "[LightGBM] [Info] Number of data points in the train set: 777943, number of used features: 34\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.203131 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1718\n",
      "[LightGBM] [Info] Number of data points in the train set: 777944, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 6.470364\n",
      "[LightGBM] [Info] Start training from score 6.468315\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.157704 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1724\n",
      "[LightGBM] [Info] Number of data points in the train set: 777943, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 6.470364\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Wendo99/miniconda3/envs/NYC_Taxi/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/Wendo99/miniconda3/envs/NYC_Taxi/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/Wendo99/miniconda3/envs/NYC_Taxi/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.046204 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1724\n",
      "[LightGBM] [Info] Number of data points in the train set: 777943, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 6.470364\n",
      "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.104252 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1718\n",
      "[LightGBM] [Info] Number of data points in the train set: 777944, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 6.468315\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.080303 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1729\n",
      "[LightGBM] [Info] Number of data points in the train set: 777943, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 6.469957\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Wendo99/miniconda3/envs/NYC_Taxi/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Wendo99/miniconda3/envs/NYC_Taxi/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Wendo99/miniconda3/envs/NYC_Taxi/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.044523 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1724\n",
      "[LightGBM] [Info] Number of data points in the train set: 777943, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 6.470364\n",
      "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.050983 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1718\n",
      "[LightGBM] [Info] Number of data points in the train set: 777944, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 6.468315\n",
      "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.049869 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1729\n",
      "[LightGBM] [Info] Number of data points in the train set: 777943, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 6.469957\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Wendo99/miniconda3/envs/NYC_Taxi/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.041315 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1724\n",
      "[LightGBM] [Info] Number of data points in the train set: 777943, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 6.470364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Wendo99/miniconda3/envs/NYC_Taxi/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.056466 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1718\n",
      "[LightGBM] [Info] Number of data points in the train set: 777944, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 6.468315\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Wendo99/miniconda3/envs/NYC_Taxi/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Wendo99/miniconda3/envs/NYC_Taxi/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.057208 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1729\n",
      "[LightGBM] [Info] Number of data points in the train set: 777943, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 6.469957\n",
      "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.062379 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1724\n",
      "[LightGBM] [Info] Number of data points in the train set: 777943, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 6.470364\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Wendo99/miniconda3/envs/NYC_Taxi/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Wendo99/miniconda3/envs/NYC_Taxi/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.040647 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1718\n",
      "[LightGBM] [Info] Number of data points in the train set: 777944, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 6.468315\n",
      "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.057956 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1729\n",
      "[LightGBM] [Info] Number of data points in the train set: 777943, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 6.469957\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Wendo99/miniconda3/envs/NYC_Taxi/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Wendo99/miniconda3/envs/NYC_Taxi/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/Wendo99/miniconda3/envs/NYC_Taxi/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.053932 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1724\n",
      "[LightGBM] [Info] Number of data points in the train set: 777943, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 6.470364\n",
      "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.056623 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1729\n",
      "[LightGBM] [Info] Number of data points in the train set: 777943, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 6.469957\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.057005 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1718\n",
      "[LightGBM] [Info] Number of data points in the train set: 777944, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 6.468315\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Wendo99/miniconda3/envs/NYC_Taxi/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.048528 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1724\n",
      "[LightGBM] [Info] Number of data points in the train set: 777943, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 6.470364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Wendo99/miniconda3/envs/NYC_Taxi/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.046652 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1718\n",
      "[LightGBM] [Info] Number of data points in the train set: 777944, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 6.468315\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Wendo99/miniconda3/envs/NYC_Taxi/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.044598 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1729\n",
      "[LightGBM] [Info] Number of data points in the train set: 777943, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 6.469957\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Wendo99/miniconda3/envs/NYC_Taxi/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.056362 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1724\n",
      "[LightGBM] [Info] Number of data points in the train set: 777943, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 6.470364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Wendo99/miniconda3/envs/NYC_Taxi/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Wendo99/miniconda3/envs/NYC_Taxi/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.041189 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1718\n",
      "[LightGBM] [Info] Number of data points in the train set: 777944, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 6.468315\n",
      "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.049940 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1729\n",
      "[LightGBM] [Info] Number of data points in the train set: 777943, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 6.469957\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Wendo99/miniconda3/envs/NYC_Taxi/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.046627 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1724\n",
      "[LightGBM] [Info] Number of data points in the train set: 777943, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 6.470364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Wendo99/miniconda3/envs/NYC_Taxi/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.056668 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1718\n",
      "[LightGBM] [Info] Number of data points in the train set: 777944, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 6.468315\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Wendo99/miniconda3/envs/NYC_Taxi/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.052527 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1729\n",
      "[LightGBM] [Info] Number of data points in the train set: 777943, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 6.469957\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Wendo99/miniconda3/envs/NYC_Taxi/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.045365 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1724\n",
      "[LightGBM] [Info] Number of data points in the train set: 777943, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 6.470364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Wendo99/miniconda3/envs/NYC_Taxi/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.059320 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1718\n",
      "[LightGBM] [Info] Number of data points in the train set: 777944, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 6.468315\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Wendo99/miniconda3/envs/NYC_Taxi/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Wendo99/miniconda3/envs/NYC_Taxi/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Wendo99/miniconda3/envs/NYC_Taxi/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Wendo99/miniconda3/envs/NYC_Taxi/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Wendo99/miniconda3/envs/NYC_Taxi/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Wendo99/miniconda3/envs/NYC_Taxi/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Wendo99/miniconda3/envs/NYC_Taxi/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Wendo99/miniconda3/envs/NYC_Taxi/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Wendo99/miniconda3/envs/NYC_Taxi/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Wendo99/miniconda3/envs/NYC_Taxi/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.027966 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1719\n",
      "[LightGBM] [Info] Number of data points in the train set: 1166915, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 6.469545\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Best LGBM CV log-RMSE: 0.3943972072517839\n",
      "Best LGBM hyper-parameters: {'model__num_leaves': 63, 'model__n_estimators': 600, 'model__max_depth': 8, 'model__learning_rate': 0.1, 'model__feature_fraction': 0.8, 'model__bagging_freq': 0, 'model__bagging_fraction': 0.8}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Wendo99/miniconda3/envs/NYC_Taxi/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "Hold-out LGBM RMSE: 0.15765329434686484\n"
     ]
    }
   ],
   "execution_count": 35
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Model Factories",
   "id": "66dbfdf4d03b8249"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## exp1 Training – All Models – All Features",
   "id": "3af5aee63539338e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-18T05:05:21.382060Z",
     "start_time": "2025-06-18T05:03:48.483106Z"
    }
   },
   "cell_type": "code",
   "source": [
    "models_all = make_all_models(preprocessing)\n",
    "\n",
    "result_all_models = get_display_models_results(\n",
    "    models_all,\n",
    "    X_train, y_train\n",
    ")\n",
    "compare_models_results(result_all_models, seconds=True)"
   ],
   "id": "520518999823306",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.020362 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1729\n",
      "[LightGBM] [Info] Number of data points in the train set: 777943, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 6.469957\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Wendo99/miniconda3/envs/NYC_Taxi/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.022563 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1724\n",
      "[LightGBM] [Info] Number of data points in the train set: 777943, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 6.470364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Wendo99/miniconda3/envs/NYC_Taxi/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.021207 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1718\n",
      "[LightGBM] [Info] Number of data points in the train set: 777944, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 6.468315\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Wendo99/miniconda3/envs/NYC_Taxi/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 800x400 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "              Model  log-RMSE (mean)  log-RMSE (std)  RMSE (sec)\n",
       "6           XGBoost         0.398900        0.003260       0.490\n",
       "5          LightGBM         0.398920        0.003297       0.490\n",
       "3      DecisionTree         0.447364        0.000687       0.564\n",
       "4      RandomForest         0.469036        0.010992       0.598\n",
       "1             Ridge         0.563941        0.000636       0.758\n",
       "0  LinearRegression         0.563941        0.000636       0.758\n",
       "2             Lasso         0.564209        0.000615       0.758"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>log-RMSE (mean)</th>\n",
       "      <th>log-RMSE (std)</th>\n",
       "      <th>RMSE (sec)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.398900</td>\n",
       "      <td>0.003260</td>\n",
       "      <td>0.490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>0.398920</td>\n",
       "      <td>0.003297</td>\n",
       "      <td>0.490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DecisionTree</td>\n",
       "      <td>0.447364</td>\n",
       "      <td>0.000687</td>\n",
       "      <td>0.564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>0.469036</td>\n",
       "      <td>0.010992</td>\n",
       "      <td>0.598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ridge</td>\n",
       "      <td>0.563941</td>\n",
       "      <td>0.000636</td>\n",
       "      <td>0.758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>0.563941</td>\n",
       "      <td>0.000636</td>\n",
       "      <td>0.758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lasso</td>\n",
       "      <td>0.564209</td>\n",
       "      <td>0.000615</td>\n",
       "      <td>0.758</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 38
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Top Features",
   "id": "371b6d262ed6a646"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-18T05:05:57.924850Z",
     "start_time": "2025-06-18T05:05:21.821162Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for name, pipe in models_all.items():\n",
    "  pipe.fit(X_train, y_train)"
   ],
   "id": "56655ea3dff86be7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.029398 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1719\n",
      "[LightGBM] [Info] Number of data points in the train set: 1166915, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 6.469545\n"
     ]
    }
   ],
   "execution_count": 39
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-18T05:06:02.731765Z",
     "start_time": "2025-06-18T05:05:58.350615Z"
    }
   },
   "cell_type": "code",
   "source": [
    "linreg_model = models_all['LinearRegression']\n",
    "plot_lin_feature_importance(linreg_model, X_train, y_train)"
   ],
   "id": "72b23769bbdc9b9d",
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "Estimator functiontransformer does not provide get_feature_names_out. Did you mean to call pipeline[:-1].get_feature_names_out()?",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mAttributeError\u001B[39m                            Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[40]\u001B[39m\u001B[32m, line 2\u001B[39m\n\u001B[32m      1\u001B[39m linreg_model = models_all[\u001B[33m'\u001B[39m\u001B[33mLinearRegression\u001B[39m\u001B[33m'\u001B[39m]\n\u001B[32m----> \u001B[39m\u001B[32m2\u001B[39m plot_lin_feature_importance(linreg_model, X_train, y_train)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Documents/50-Apps/PyCharm/NYC_Taxi/modelling/feature_importance.py:35\u001B[39m, in \u001B[36mplot_lin_feature_importance\u001B[39m\u001B[34m(pipeline, X_train, y_train, model_step, pre_step)\u001B[39m\n\u001B[32m     32\u001B[39m \u001B[38;5;28;01melif\u001B[39;00m coefs.ndim > \u001B[32m1\u001B[39m:\n\u001B[32m     33\u001B[39m   \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[33m\"\u001B[39m\u001B[33mMulti-output regression not supported.\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m---> \u001B[39m\u001B[32m35\u001B[39m feature_names = pipeline.named_steps[pre_step].get_feature_names_out()\n\u001B[32m     37\u001B[39m feat_df = pd.DataFrame({\n\u001B[32m     38\u001B[39m   \u001B[33m'\u001B[39m\u001B[33mfeature\u001B[39m\u001B[33m'\u001B[39m: feature_names,\n\u001B[32m     39\u001B[39m   \u001B[33m'\u001B[39m\u001B[33mimportance\u001B[39m\u001B[33m'\u001B[39m: np.abs(coefs),\n\u001B[32m     40\u001B[39m   \u001B[33m'\u001B[39m\u001B[33msign\u001B[39m\u001B[33m'\u001B[39m: np.sign(coefs)\n\u001B[32m     41\u001B[39m }).sort_values(by=\u001B[33m'\u001B[39m\u001B[33mimportance\u001B[39m\u001B[33m'\u001B[39m, ascending=\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[32m     43\u001B[39m _plot_feature_bar(feat_df, \u001B[32m20\u001B[39m, \u001B[33m\"\u001B[39m\u001B[33mTop 20 feature importances\u001B[39m\u001B[33m\"\u001B[39m)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/miniconda3/envs/NYC_Taxi/lib/python3.12/site-packages/sklearn/compose/_column_transformer.py:646\u001B[39m, in \u001B[36mColumnTransformer.get_feature_names_out\u001B[39m\u001B[34m(self, input_features)\u001B[39m\n\u001B[32m    639\u001B[39m transformer_with_feature_names_out = []\n\u001B[32m    640\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m name, trans, *_ \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m._iter(\n\u001B[32m    641\u001B[39m     fitted=\u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[32m    642\u001B[39m     column_as_labels=\u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[32m    643\u001B[39m     skip_empty_columns=\u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[32m    644\u001B[39m     skip_drop=\u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[32m    645\u001B[39m ):\n\u001B[32m--> \u001B[39m\u001B[32m646\u001B[39m     feature_names_out = \u001B[38;5;28mself\u001B[39m._get_feature_name_out_for_transformer(\n\u001B[32m    647\u001B[39m         name, trans, input_features\n\u001B[32m    648\u001B[39m     )\n\u001B[32m    649\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m feature_names_out \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m    650\u001B[39m         \u001B[38;5;28;01mcontinue\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/miniconda3/envs/NYC_Taxi/lib/python3.12/site-packages/sklearn/compose/_column_transformer.py:613\u001B[39m, in \u001B[36mColumnTransformer._get_feature_name_out_for_transformer\u001B[39m\u001B[34m(self, name, trans, feature_names_in)\u001B[39m\n\u001B[32m    608\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(trans, \u001B[33m\"\u001B[39m\u001B[33mget_feature_names_out\u001B[39m\u001B[33m\"\u001B[39m):\n\u001B[32m    609\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mAttributeError\u001B[39;00m(\n\u001B[32m    610\u001B[39m         \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mTransformer \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mname\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m (type \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mtype\u001B[39m(trans).\u001B[34m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m) does \u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    611\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33mnot provide get_feature_names_out.\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    612\u001B[39m     )\n\u001B[32m--> \u001B[39m\u001B[32m613\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m trans.get_feature_names_out(names)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/miniconda3/envs/NYC_Taxi/lib/python3.12/site-packages/sklearn/pipeline.py:1276\u001B[39m, in \u001B[36mPipeline.get_feature_names_out\u001B[39m\u001B[34m(self, input_features)\u001B[39m\n\u001B[32m   1274\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m _, name, transform \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m._iter():\n\u001B[32m   1275\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(transform, \u001B[33m\"\u001B[39m\u001B[33mget_feature_names_out\u001B[39m\u001B[33m\"\u001B[39m):\n\u001B[32m-> \u001B[39m\u001B[32m1276\u001B[39m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mAttributeError\u001B[39;00m(\n\u001B[32m   1277\u001B[39m             \u001B[33m\"\u001B[39m\u001B[33mEstimator \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[33m does not provide get_feature_names_out. \u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m   1278\u001B[39m             \u001B[33m\"\u001B[39m\u001B[33mDid you mean to call pipeline[:-1].get_feature_names_out\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m   1279\u001B[39m             \u001B[33m\"\u001B[39m\u001B[33m()?\u001B[39m\u001B[33m\"\u001B[39m.format(name)\n\u001B[32m   1280\u001B[39m         )\n\u001B[32m   1281\u001B[39m     feature_names_out = transform.get_feature_names_out(feature_names_out)\n\u001B[32m   1282\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m feature_names_out\n",
      "\u001B[31mAttributeError\u001B[39m: Estimator functiontransformer does not provide get_feature_names_out. Did you mean to call pipeline[:-1].get_feature_names_out()?"
     ]
    }
   ],
   "execution_count": 40
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "lasso_model = models_all['Lasso']\n",
    "plot_lin_feature_importance(lasso_model, X_train, y_train)"
   ],
   "id": "165f9714b263df12",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "ridge_model = models_all['Ridge']\n",
    "plot_lin_feature_importance(ridge_model, X_train, y_train)"
   ],
   "id": "5e014afa5dda556f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "xgb_model = models_all['XGBoost']\n",
    "plot_tree_feature_importance(xgb_model, X_train, y_train)"
   ],
   "id": "da9212f1fb9e3471",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "lgbm_model = models_all['LightGBM']\n",
    "plot_tree_feature_importance(lgbm_model, X_train, y_train)"
   ],
   "id": "d4e4a9374e018892",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "dt_model = models_all['DecisionTree']\n",
    "plot_tree_feature_importance(dt_model, X_train, y_train)"
   ],
   "id": "8fe877660d189231",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "rf_model = models_all['RandomForest']\n",
    "plot_tree_feature_importance(rf_model, X_train, y_train)"
   ],
   "id": "346a54949a0d7ae0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "e2f4cafc72870d5d"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
